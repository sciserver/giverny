{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accessing turbulence isotropic cube files on filedb cluster from sciserver\n",
    "* created volume container (turb) showing all /turb folders on filedb system\n",
    "* access to turbinfo for metadata about these files\n",
    " * requires copying DataPath table\n",
    "* morton curve code pip installed in sciserver container\n",
    "* some special code to take into account 8x8x8 blobs with z-y-x ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install morton-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import morton\n",
    "import struct\n",
    "import numpy as np\n",
    "import SciServer.CasJobs as cj\n",
    "\n",
    "class IsoCube:\n",
    "    def __init__(self, cube_num, cube_dimensions = 3, cube_subtitle = ''):\n",
    "        # setting up Morton curve\n",
    "        # cube size\n",
    "        # the assumed name of the dataset names are \"isotropic{N}\" (e.g. \"isotropic8192\")\n",
    "        self.N = cube_num\n",
    "        # if the turbulence database has a sub title (e.g. \"isotropic1024fine\" or \"isotropic1024coarse\"), specify\n",
    "        # the subtitle here.  otherwise leave this as an empty string.\n",
    "        self.N_subtitle = cube_subtitle\n",
    "        bits = int(math.log(self.N,2))\n",
    "        self.mortoncurve = morton.Morton(dimensions = cube_dimensions, bits = bits)\n",
    "        self.initcache()\n",
    "        \n",
    "    def initcache(self):\n",
    "        # read SQL metadata for all of the turbulence data files into the cache\n",
    "        sql = f\"\"\"\n",
    "        select dbm.ProductionMachineName\n",
    "        , dbm.ProductionDatabaseName\n",
    "        , dbm.minLim, dbm.maxLim\n",
    "        , dbm.minTime, dbm.maxTime\n",
    "        , dp.path\n",
    "        from databasemap dbm\n",
    "           join datapath{str(self.N) + self.N_subtitle} dp\n",
    "             on dp.datasetid=dbm.datasetid\n",
    "           and dp.productionmachinename=dbm.productionmachinename\n",
    "           and dp.ProductionDatabaseName=dbm.ProductionDatabaseName\n",
    "        where dbm.datasetname = 'isotropic{str(self.N) + self.N_subtitle}'\n",
    "        order by minlim\n",
    "        \"\"\"\n",
    "        df = cj.executeQuery(sql, \"turbinfo\")\n",
    "        \n",
    "        x, y, z = self.mortoncurve.unpack(df['minLim'].values)\n",
    "        df['x_min'] = x\n",
    "        df['y_min'] = y\n",
    "        df['z_min'] = z\n",
    "        \n",
    "        x, y, z = self.mortoncurve.unpack(df['maxLim'].values)\n",
    "        df['x_max'] = x\n",
    "        df['y_max'] = y \n",
    "        df['z_max'] = z\n",
    "        \n",
    "        self.cache = df\n",
    "    \n",
    "    # defines some helper functions, all hardcoded (double-check this when other datasets are available)\n",
    "    def parseCornerPoints(self, x_min, x_max, y_min, y_max, z_min, z_max):\n",
    "        # only points 1, 2, 4, and 5 are required for finding the correct sub-boxes.\n",
    "        # corner 1 is the bottom left back side origin point.\n",
    "        # corner 2 is the bottom right back side corner point (same as corner 1 except at the maximum x-position).\n",
    "        # corner 4 is the bottom left front side corner point (same as corner 1 except at the maximum y-positon).\n",
    "        # corner 5 is the top left back corner point (same as corner 1 except at the maximum z-positon).\n",
    "        # corners 2, 3, and 4 travel around the bottom plane of the box clockwise from corner 1.\n",
    "        # corners 6, 7, and 8 travel around the top plane of the box clockwise from corner 5.\n",
    "        c1 = (x_min, y_min, z_min)\n",
    "        c2 = (x_max, y_min, z_min)\n",
    "        #c3 = (x_max, y_max, z_min)\n",
    "        c4 = (x_min, y_max, z_min)\n",
    "        c5 = (x_min, y_min, z_max)\n",
    "        #c6 = (x_max, y_min, z_max)\n",
    "        #c7 = (x_max, y_max, z_max)\n",
    "        #c8 = (x_min, y_max, z_max)\n",
    "        \n",
    "        corner_points = (c1, c2, c4, c5)\n",
    "        \n",
    "        return corner_points\n",
    "        \n",
    "    def getFilesForCornerPoints(self, x_range, y_range, z_range, var, timepoint):\n",
    "        # define the corner points.\n",
    "        x_min = x_range[0]; x_max = x_range[1];\n",
    "        y_min = y_range[0]; y_max = y_range[1];\n",
    "        z_min = z_range[0]; z_max = z_range[1];\n",
    "        \n",
    "        # retrieve the corner points.\n",
    "        c_points = self.parseCornerPoints(x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "        \n",
    "        database_files = []\n",
    "        \n",
    "        # only points 1, 2, 4, and 5 are required for finding the correct sub-boxes.\n",
    "        c1_info = self.getFileForPoint(c_points[0][0], c_points[0][1], c_points[0][2], var, timepoint)\n",
    "        c1_file = c1_info[0]\n",
    "        database_files.append(c1_file)\n",
    "        \n",
    "        c2_info = self.getFileForPoint(c_points[1][0], c_points[1][1], c_points[1][2], var, timepoint)\n",
    "        c2_file = c2_info[0]\n",
    "        database_files.append(c2_file)\n",
    "        \n",
    "        c4_info = self.getFileForPoint(c_points[2][0], c_points[2][1], c_points[2][2], var, timepoint)\n",
    "        c4_file = c4_info[0]\n",
    "        database_files.append(c4_file)\n",
    "        \n",
    "        c5_info = self.getFileForPoint(c_points[3][0], c_points[3][1], c_points[3][2], var, timepoint)\n",
    "        c5_file = c5_info[0]\n",
    "        database_files.append(c5_file)\n",
    "        \n",
    "        return database_files\n",
    "    \n",
    "    def findSubBoxEndPoint(self, axis_range, datapoint, axis_position, db_file_comparison, var, timepoint):\n",
    "        # placeholder end point value. \n",
    "        end_point = -1\n",
    "        # if the difference between the axis range end points is <= to this value, then the end_point\n",
    "        # has been found.\n",
    "        axis_range_difference = 2\n",
    "        \n",
    "        end_point_found = False\n",
    "        while not end_point_found:\n",
    "            mid_point = math.floor((axis_range[0] + axis_range[1]) / 2)\n",
    "            \n",
    "            # stops recursively shrinking the box once the difference between the two end points is <= axis_range_difference.\n",
    "            if (axis_range[1] - axis_range[0]) <= axis_range_difference:\n",
    "                end_point_found = True\n",
    "            \n",
    "            # updates the datapoint to the new mid point.\n",
    "            datapoint[axis_position] = mid_point\n",
    "            \n",
    "            # gets the db file for the new datapoint.\n",
    "            datapoint_info = self.getFileForPoint(datapoint[0], datapoint[1], datapoint[2], var, timepoint)\n",
    "            datapoint_file = datapoint_info[0]\n",
    "            \n",
    "            # compares the db file for datapoint to the origin point.\n",
    "            if datapoint_file == db_file_comparison:\n",
    "                end_point = mid_point\n",
    "                axis_range[0] = mid_point\n",
    "            else:\n",
    "                end_point = mid_point - 1\n",
    "                axis_range[1] = mid_point\n",
    "            \n",
    "            # used for checking that there were no redundant calculations\n",
    "            #print(f'midpoint = {mid_point}')\n",
    "            #print(f'endpoint = {end_point}')\n",
    "            #print('-')\n",
    "                \n",
    "        return end_point\n",
    "    \n",
    "    def identifySingleDatabaseFileSubBoxes(self, x_range, y_range, z_range, var, timepoint):\n",
    "        # initially assumes the user specified box contains points in different files. the boxes will be split up until all the points\n",
    "        # in each box are from a single database file.\n",
    "        boxes_to_check = [(x_range, y_range, z_range)]\n",
    "        single_file_boxes = {}\n",
    "        \n",
    "        while len(boxes_to_check) != 0:\n",
    "            for box in reversed(boxes_to_check):\n",
    "                db_files = self.getFilesForCornerPoints(box[0], box[1], box[2], var, timepoint)\n",
    "                num_db_files = len(set(db_files))\n",
    "                \n",
    "                if num_db_files == 1:\n",
    "                    single_file_boxes[list(set(db_files))[0]] = box \n",
    "                elif db_files[0] != db_files[1]:\n",
    "                    # this means that the x_range was sufficiently large such that all of the points were\n",
    "                    # not contained in a singular database file.  i.e. the database files were different for\n",
    "                    # corners 1 and 2.  the data x_range will now be split in half to create 2 sub-boxes for checking.\n",
    "                    \n",
    "                    # this value is specified as 0 because the x-axis index is 0.  this is used for determing which \n",
    "                    # point (X, Y, or Z) the midpoint is going to be tested for.  in this case, this section of code\n",
    "                    # is adjusting only the x-axis.\n",
    "                    axis_position = 0\n",
    "                    # stores the c1 corner point (X, Y, Z) of the box to be used for finding the first box end point\n",
    "                    # when shrinking the x-axis into sub-boxes.\n",
    "                    datapoint = [box[0][0], box[1][0], box[2][0]]\n",
    "                    # which axis is sub-divided, in this case it is the x-axis.\n",
    "                    axis_range = list(box[0])\n",
    "                    # determine where the end x-axis point is for the first sub-box.\n",
    "                    first_box_end_point = self.findSubBoxEndPoint(axis_range, datapoint, axis_position, db_files[0], \\\n",
    "                                                                  var, timepoint)\n",
    "                    \n",
    "                    first_sub_box = [[box[0][0], first_box_end_point], box[1], box[2]]\n",
    "                    second_sub_box = [[first_box_end_point + 1, box[0][1]], box[1], box[2]]\n",
    "                    \n",
    "                    boxes_to_check.append(second_sub_box)\n",
    "                    boxes_to_check.append(first_sub_box)\n",
    "                elif db_files[0] != db_files[2]:\n",
    "                    # this means that the y_range was sufficiently large such that all of the points were\n",
    "                    # not contained in a singular database file.  i.e. the database files were different for\n",
    "                    # corners 1 and 4.  the data y_range will now be split in half to create 2 sub-boxes for checking.\n",
    "                    \n",
    "                    # this value is specified as 1 because the y-axis index is 1.  this is used for determing which \n",
    "                    # point (X, Y, or Z) the midpoint is going to be tested for.  in this case, this section of code\n",
    "                    # is adjusting only the y-axis.\n",
    "                    axis_position = 1\n",
    "                    # stores the c1 corner point (X, Y, Z) of the box to be used for finding the first box end point \n",
    "                    # when shrinking the y-axis into sub-boxes.\n",
    "                    datapoint = [box[0][0], box[1][0], box[2][0]]\n",
    "                    # which axis is sub-divided, in this case it is the y-axis.\n",
    "                    axis_range = list(box[1])\n",
    "                    # determine where the end y-axis point is for the first sub-box.\n",
    "                    first_box_end_point = self.findSubBoxEndPoint(axis_range, datapoint, axis_position, db_files[0], \\\n",
    "                                                                  var, timepoint)\n",
    "                    \n",
    "                    first_sub_box = [box[0], [box[1][0], first_box_end_point], box[2]]\n",
    "                    second_sub_box = [box[0], [first_box_end_point + 1, box[1][1]], box[2]]\n",
    "                    \n",
    "                    boxes_to_check.append(second_sub_box)\n",
    "                    boxes_to_check.append(first_sub_box)\n",
    "                elif db_files[0] != db_files[3]:\n",
    "                    # this means that the z_range was sufficiently large such that all of the points were\n",
    "                    # not contained in a singular database file.  i.e. the database files were different for\n",
    "                    # corners 1 and 5.  the data z_range will now be split in half to create 2 sub-boxes for checking.\n",
    "                    \n",
    "                    # this value is specified as 2 because the z-axis index is 2.  this is used for determing which \n",
    "                    # point (X, Y, or Z) the midpoint is going to be tested for.  in this case, this section of code\n",
    "                    # is adjusting only the z-axis.\n",
    "                    axis_position = 2\n",
    "                    # stores the c1 corner point (X, Y, Z) of the box to be used for finding the first box end point \n",
    "                    # when shrinking the z-axis into sub-boxes.\n",
    "                    datapoint = [box[0][0], box[1][0], box[2][0]]\n",
    "                    # which axis is sub-divided, in this case it is the z-axis.\n",
    "                    axis_range = list(box[2])\n",
    "                    # determine where the end z-axis point is for the first sub-box.\n",
    "                    first_box_end_point = self.findSubBoxEndPoint(axis_range, datapoint, axis_position, db_files[0], \\\n",
    "                                                                  var, timepoint)\n",
    "                    \n",
    "                    first_sub_box = [box[0], box[1], [box[2][0], first_box_end_point]]\n",
    "                    second_sub_box = [box[0], box[1], [first_box_end_point + 1, box[2][1]]]\n",
    "                    \n",
    "                    boxes_to_check.append(second_sub_box)\n",
    "                    boxes_to_check.append(first_sub_box)\n",
    "                    \n",
    "                # either the original box is fully contained in a single database file, or it is in more than one.\n",
    "                # in either case, the box should be removed from further checking.  the sub-boxes will be checked\n",
    "                # if necessary.\n",
    "                boxes_to_check.remove(box)\n",
    "            \n",
    "        return single_file_boxes\n",
    "    \n",
    "    def boxesContained(self, sub_box, user_box):\n",
    "        contained = False\n",
    "        # checks if the sub-divided box is fully contained within the user-specified box.\n",
    "        if (sub_box[0][0] >= user_box[0][0] and sub_box[0][1] <= user_box[0][1]) and \\\n",
    "            (sub_box[1][0] >= user_box[1][0] and sub_box[1][1] <= user_box[1][1]) and \\\n",
    "            (sub_box[2][0] >= user_box[2][0] and sub_box[2][1] <= user_box[2][1]):\n",
    "            contained = True\n",
    "        \n",
    "        return contained\n",
    "    \n",
    "    def boxesOverlap(self, sub_box, user_box):\n",
    "        overlap = False\n",
    "        # checks if the sub-divided box and the user-specified box overlap on all 3 axes\n",
    "        if (sub_box[0][0] <= user_box[0][1] and user_box[0][0] <= sub_box[0][1]) and \\\n",
    "            (sub_box[1][0] <= user_box[1][1] and user_box[1][0] <= sub_box[1][1]) and \\\n",
    "            (sub_box[2][0] <= user_box[2][1] and user_box[2][0] <= sub_box[2][1]):\n",
    "            overlap = True\n",
    "            \n",
    "        return overlap\n",
    "    \n",
    "    def recursiveSubBoxesInFile(self, box, user_db_box, sub_boxes):\n",
    "        # recursively sub-divides the database file cube until the entire user-specified box is mapped by morton cubes\n",
    "        box_x_range = box[0]\n",
    "        box_y_range = box[1]\n",
    "        box_z_range = box[2]\n",
    "        \n",
    "        # checks if the sub-box corner points are all inside the portion of the user-specified box in the database file.\n",
    "        box_fully_contained = self.boxesContained(box, user_db_box)\n",
    "        if box_fully_contained:\n",
    "            # converts the box (X, Y, Z) minimum and maximum points to morton indices\n",
    "            morton_index_min = self.mortoncurve.pack(box[0][0], box[1][0], box[2][0])\n",
    "            morton_index_max = self.mortoncurve.pack(box[0][1], box[1][1], box[2][1])\n",
    "            \n",
    "            if sub_boxes == list():\n",
    "                sub_boxes.append([morton_index_min, morton_index_max])\n",
    "            else:\n",
    "                # check if the most recent sub-box maximum is 1 index less than the new sub-box minimum.  if so, then extend the range of the previous sub-box\n",
    "                # morton maximum to stitch these two boxes together.\n",
    "                if sub_boxes[-1][1] == (morton_index_min - 1):\n",
    "                    sub_boxes[-1][1] = morton_index_max\n",
    "                else:\n",
    "                    sub_boxes.append([morton_index_min, morton_index_max])\n",
    "            \n",
    "            return\n",
    "        else:\n",
    "            box_partially_contained = self.boxesOverlap(box, user_db_box)\n",
    "            if box_partially_contained:\n",
    "                # sub-divide the box into 8 sub-cubes (divide the x-, y-, and z- axes in half) and recursively check each box if it is inside the user-specified\n",
    "                # box, if necessary.\n",
    "                box_x_range_midpoint = math.floor((box_x_range[0] + box_x_range[1]) / 2)\n",
    "                box_y_range_midpoint = math.floor((box_y_range[0] + box_y_range[1]) / 2)\n",
    "                box_z_range_midpoint = math.floor((box_z_range[0] + box_z_range[1]) / 2)\n",
    "                \n",
    "                # ordering sub-boxes 1-8 below in this order maintains the morton-curve index structure, such that the minimum (X, Y, Z) morton index \n",
    "                # for a new box only needs to be compared to the last sub-boxes' maximum (X, Y, Z) morton index to see if they can be stitched together.\n",
    "                \n",
    "                # new_sub_box_1 is the sub-box bounded by [x_min, x_midpoint], [y_min, y_midpoint], and [z_min, z_midpoint]\n",
    "                # new_sub_box_2 is the sub-box bounded by [x_midpoint + 1, x_max], [y_min, y_midpoint], and [z_min, z_midpoint]\n",
    "                # new_sub_box_3 is the sub-box bounded by [x_min, x_midpoint], [y_midpoint + 1, y_max], and [z_min, z_midpoint]\n",
    "                # new_sub_box_4 is the sub-box bounded by [x_midpoint + 1, x_max], [y_midpoint + 1, y_max], and [z_min, z_midpoint]\n",
    "                new_sub_box_1 = [[box_x_range[0], box_x_range_midpoint], [box_y_range[0], box_y_range_midpoint], [box_z_range[0], box_z_range_midpoint]]\n",
    "                new_sub_box_2 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range[0], box_y_range_midpoint], [box_z_range[0], box_z_range_midpoint]]\n",
    "                new_sub_box_3 = [[box_x_range[0], box_x_range_midpoint], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range[0], box_z_range_midpoint]]\n",
    "                new_sub_box_4 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range[0], box_z_range_midpoint]]\n",
    "                \n",
    "                # new_sub_box_5 is the sub-box bounded by [x_min, x_midpoint], [y_min, y_midpoint], and [z_midpoint + 1, z_max]\n",
    "                # new_sub_box_6 is the sub-box bounded by [x_midpoint + 1, x_max], [y_min, y_midpoint], and [z_midpoint + 1, z_max]\n",
    "                # new_sub_box_7 is the sub-box bounded by [x_min, x_midpoint], [y_midpoint + 1, y_max], and [z_midpoint + 1, z_max]\n",
    "                # new_sub_box_8 is the sub-box bounded by [x_midpoint + 1, x_max], [y_midpoint + 1, y_max], and [z_midpoint + 1, z_max]\n",
    "                new_sub_box_5 = [[box_x_range[0], box_x_range_midpoint], [box_y_range[0], box_y_range_midpoint], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "                new_sub_box_6 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range[0], box_y_range_midpoint], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "                new_sub_box_7 = [[box_x_range[0], box_x_range_midpoint], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "                new_sub_box_8 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "\n",
    "                new_sub_boxes = []\n",
    "                new_sub_boxes.append(new_sub_box_1)\n",
    "                new_sub_boxes.append(new_sub_box_2)\n",
    "                new_sub_boxes.append(new_sub_box_3)\n",
    "                new_sub_boxes.append(new_sub_box_4)\n",
    "                new_sub_boxes.append(new_sub_box_5)\n",
    "                new_sub_boxes.append(new_sub_box_6)\n",
    "                new_sub_boxes.append(new_sub_box_7)\n",
    "                new_sub_boxes.append(new_sub_box_8)\n",
    "                    \n",
    "                for new_sub_box in new_sub_boxes:\n",
    "                    # checks if a sub-box is at least partially contained inside the user-specified box. if so, then the sub-box will be recursively searched \n",
    "                    # until an entire sub-box is inside the user-specified box\n",
    "                    new_sub_box_partially_contained = self.boxesOverlap(new_sub_box, user_db_box)\n",
    "\n",
    "                    if new_sub_box_partially_contained:\n",
    "                        self.recursiveSubBoxesInFile(new_sub_box, user_db_box, sub_boxes)\n",
    "        return\n",
    "        \n",
    "    def identifySubBoxesInFile(self, user_db_box, var, timepoint):\n",
    "        # initially assumes the user-specified box in the file is not the entire box representing the file. the database file box will be sub-divided into\n",
    "        # morton cubes until the user-specified box is completely mapped by all of these sub-cubes.\n",
    "        user_db_box_x_range = user_db_box[0]\n",
    "        user_db_box_y_range = user_db_box[1]\n",
    "        user_db_box_z_range = user_db_box[2]\n",
    "        \n",
    "        user_db_box_x_min = user_db_box_x_range[0]\n",
    "        user_db_box_y_min = user_db_box_y_range[0]\n",
    "        user_db_box_z_min = user_db_box_z_range[0]\n",
    "        \n",
    "        # retrieve the morton index limits (minLim, maxLim) of the cube representing the whole database file\n",
    "        f, cornercode, offset, minLim, maxLim = self.getFileForPoint(user_db_box_x_min, user_db_box_y_min, user_db_box_z_min, var, timepoint)\n",
    "        minLim_xyz = self.mortoncurve.unpack(minLim)\n",
    "        maxLim_xyz = self.mortoncurve.unpack(maxLim)\n",
    "        \n",
    "        # get the box for the entire database file so that it can be recursively broken down into cubes\n",
    "        db_box = [[minLim_xyz[0], maxLim_xyz[0]], [minLim_xyz[1], maxLim_xyz[1]], [minLim_xyz[2], maxLim_xyz[2]]]\n",
    "        \n",
    "        # these are the constituent file sub-cubes that make up the part of the user-specified box in the database file\n",
    "        sub_boxes = []\n",
    "        self.recursiveSubBoxesInFile(db_box, user_db_box, sub_boxes)\n",
    "\n",
    "        return sub_boxes\n",
    "        \n",
    "    def getVelocitiesForAllPoints(self, x_range, y_range, z_range, min_step = 1):\n",
    "        # manually retrieves the velocities for all points inside the box. this is computationally expensive and not efficient, and this function is deprecated.\n",
    "        x_min = x_range[0]; x_max = x_range[1];\n",
    "        y_min = y_range[0]; y_max = y_range[1];\n",
    "        z_min = z_range[0]; z_max = z_range[1];\n",
    "        \n",
    "        current_x_max = x_max\n",
    "        current_y_max = y_max\n",
    "        current_z_max = z_max\n",
    "        \n",
    "        velocity_map = {}\n",
    "        velocity_data = np.array([-1, -1, -1])\n",
    "        for x_point in np.arange(x_min, x_max + 1, min_step):\n",
    "            for y_point in np.arange(y_min, y_max + 1, min_step):\n",
    "                for z_point in np.arange(z_min, z_max + 1, min_step):\n",
    "                    velocity_data = self.getISO_Point(x_point, y_point, z_point, var = 'vel', timepoint = 0, verbose = False)\n",
    "                    \n",
    "                    velocity_map[(x_point, y_point, z_point)] = velocity_data\n",
    "                    #print(x_point)\n",
    "                    #print(cornercode, offset)\n",
    "        \n",
    "        return velocity_map\n",
    "        \n",
    "    def getOffset(self, X, Y, Z):\n",
    "        \"\"\"\n",
    "        TODO is this code correct for velocity as well?  YES\n",
    "        \"\"\"\n",
    "        # morton curve index corresponding to the user specified X, Y, and Z values\n",
    "        code = self.mortoncurve.pack(X, Y, Z)\n",
    "        # always looking at an 8 x 8 x 8 box around the grid point, so the shift is always 9 bits to determine \n",
    "        # the bottom left corner of the box. the cornercode (bottom left corner of the 8 x 8 x 8 box) is always \n",
    "        # in the same file as the user-specified grid point.\n",
    "        # equivalent to 512 * (math.floor(code / 512))\n",
    "        cornercode = (code >> 9) << 9\n",
    "        corner = np.array(self.mortoncurve.unpack(cornercode))\n",
    "        # calculates the offset between the grid point and corner of the box and converts it to a 4-byte float.\n",
    "        offset = np.sum((np.array([X, Y, Z]) - corner) * np.array([1, 8, 64]))\n",
    "        \n",
    "        return cornercode, offset\n",
    "    \n",
    "    def getFileForPoint_nocache(self, X, Y, Z, var = 'pr', timepoint = 0):\n",
    "        \"\"\"\n",
    "        querying the SQL metadata database for the information the specific file corresponding to the user specified \n",
    "        X, Y, and Z grid point. this method is slow, and is deprecated.\n",
    "        \"\"\"\n",
    "        cornercode, offset = self.getOffset(X, Y, Z)\n",
    "        \n",
    "        sql = f\"\"\"\n",
    "        select dbm.ProductionMachineName\n",
    "        , dbm.ProductionDatabaseName\n",
    "        , dbm.minLim, dbm.maxLim\n",
    "        , dbm.minTime, dbm.maxTime\n",
    "        , dp.path\n",
    "        from databasemap dbm\n",
    "           join datapath{str(self.N) + self.N_subtitle} dp\n",
    "             on dp.datasetid=dbm.datasetid\n",
    "           and dp.productionmachinename=dbm.productionmachinename\n",
    "           and dp.ProductionDatabaseName=dbm.ProductionDatabaseName\n",
    "        where dbm.datasetname = 'isotropic{str(self.N) + self.N_subtitle}'\n",
    "        and {cornercode} between minLim and maxLim\n",
    "        order by minlim\n",
    "        \"\"\"\n",
    "        df = cj.executeQuery(sql, \"turbinfo\")\n",
    "        t = df.loc[0]\n",
    "        dataN = t.path.split(\"/\")\n",
    "        f = f'/home/idies/workspace/turb/data{t.ProductionMachineName[-2:]}_{dataN[2][-2:]}/{dataN[-1]}/{t.ProductionDatabaseName}_{var}_{timepoint}.bin'\n",
    "        return f, cornercode, offset, t.minLim\n",
    "    \n",
    "    def getFileForPoint(self, X, Y, Z, var = 'pr', timepoint = 0):\n",
    "        \"\"\"\n",
    "        querying the cached SQL metadata for the file for the user specified grid point\n",
    "        \"\"\"\n",
    "        cornercode, offset = self.getOffset(X, Y, Z)\n",
    "        t = self.cache[(self.cache['minLim'] <= cornercode) & (self.cache['maxLim'] >= cornercode)]\n",
    "        t = t.iloc[0]\n",
    "        dataN = t.path.split(\"/\")\n",
    "        f = f'/home/idies/workspace/turb/data{t.ProductionMachineName[-2:]}_{dataN[2][-2:]}/{dataN[-1]}/{t.ProductionDatabaseName}_{var}_{timepoint}.bin'\n",
    "        return f, cornercode, offset, t.minLim, t.maxLim\n",
    "        \n",
    "    def getISO_Point(self, X, Y, Z, var = 'pr', timepoint = 0, verbose = False):\n",
    "        \"\"\"\n",
    "        find the value for the specified var(iable) at the specified grid point X, Y, Z and the specified timepoint. position \n",
    "        is assumed to be a point of the grid, i.e. should be integers, and timepoint should be an integer between 0 and 5.\n",
    "        \"\"\"\n",
    "        f, cornercode, offset, minLim, maxLim = self.getFileForPoint(X, Y, Z, var, timepoint)\n",
    "        if verbose:\n",
    "            print(f, cornercode, offset, minLim, maxLim)\n",
    "            print(self.mortoncurve.unpack(minLim))\n",
    "            print(self.mortoncurve.unpack(maxLim))\n",
    "            \n",
    "        # currently two vars are accepted (pressure and velocity). both are 4 byte values, but there are 3 velocities \n",
    "        # per grid point (velocity magnitude along each dimension). \n",
    "        N = 1\n",
    "        if var == 'vel':\n",
    "            N = 3\n",
    "        \n",
    "        seek_distance = N * 4 * (cornercode + offset - minLim)\n",
    "        with open(f, 'rb') as b:\n",
    "            b.seek(seek_distance)\n",
    "            xraw = b.read(N * 4)\n",
    "            \n",
    "        l = struct.unpack('f' * N, xraw)\n",
    "        return np.asarray(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 ms, sys: 0 ns, total: 11.4 ms\n",
      "Wall time: 11.4 ms\n",
      "CPU times: user 7.89 ms, sys: 997 Âµs, total: 8.89 ms\n",
      "Wall time: 8.69 ms\n",
      "-\n",
      "number of db files that the user-specified box is found in = 1\n",
      "-\n",
      "/home/idies/workspace/turb/data09_01/iso8192db_06/iso8192db0006_vel_0.bin\n",
      "([1019, 1023], [100, 100], [1000, 1023])\n",
      "-\n",
      "sub-boxes found in the database file:\n",
      "-\n",
      "/home/idies/workspace/turb/data09_01/iso8192db_06/iso8192db0006_vel_0.bin\n",
      "number of boxes = 72\n"
     ]
    }
   ],
   "source": [
    "# gets velocity for all points inside the user specified box.\n",
    "iso_data = IsoCube(cube_num = 8192, cube_dimensions = 3, cube_subtitle = '')\n",
    "\n",
    "# user specified box rather than a singular data point.\n",
    "x_range = [1019, 1023]\n",
    "y_range = [100, 100]\n",
    "z_range = [1000, 1023]\n",
    "\n",
    "# test values for the whole grid.\n",
    "# x_range = [0, 34]\n",
    "# y_range = [0, 511]\n",
    "# z_range = [0, 511]\n",
    "\n",
    "# variable of interest, currently set to velocity.\n",
    "var = 'vel'\n",
    "\n",
    "# time point\n",
    "timepoint = 0\n",
    "\n",
    "# get a map of the database files where all the data points are in.\n",
    "%time user_single_db_boxes = iso_data.identifySingleDatabaseFileSubBoxes(x_range, y_range, z_range, var, timepoint)\n",
    "# recursively break down each single file box into sub-boxes, each of which is exactly one of the sub-divided cubes of the database file.\n",
    "sub_db_boxes = {}\n",
    "for db_file in sorted(user_single_db_boxes, key = lambda x: os.path.basename(x)):\n",
    "    user_db_box = user_single_db_boxes[db_file]\n",
    "    \n",
    "    %time sub_boxes = iso_data.identifySubBoxesInFile(user_db_box, var, timepoint)\n",
    "    \n",
    "    sub_db_boxes[db_file] = sub_boxes\n",
    "\n",
    "print(f'-\\nnumber of db files that the user-specified box is found in = {len(user_single_db_boxes)}\\n-')\n",
    "for db_file in sorted(user_single_db_boxes, key = lambda x: os.path.basename(x)):\n",
    "    print(db_file)\n",
    "    print(user_single_db_boxes[db_file])\n",
    "\n",
    "print('-\\nsub-boxes found in the database file:\\n-')\n",
    "for db_file in sorted(sub_db_boxes, key = lambda x: os.path.basename(x)):\n",
    "    print(db_file)\n",
    "    print(f'number of boxes = {len(sub_db_boxes[db_file])}')\n",
    "    #print(sub_db_boxes[db_file])\n",
    "    \n",
    "# read a file for a point.\n",
    "# print('-')\n",
    "# X = 512\n",
    "# Y = 100\n",
    "# Z = 3\n",
    "#\n",
    "# %time var_data = iso_data.getISO_Point(X, Y, Z, var, timepoint, verbose = True)\n",
    "#\n",
    "# print(f'-\\n{var} for point ({X}, {Y}, {Z}) = {var_data}')\n",
    "    \n",
    "# read the velocities for all points in the box by brute force.\n",
    "# %time velocities = iso_data.getVelocitiesForAllPoints(x_range, y_range, z_range, min_step = 1)\n",
    "#\n",
    "# print(f'\\nnum velocities = {len(v3)}\\n-')\n",
    "# for velocity_point in velocities:\n",
    "#     print(velocity_point)\n",
    "#     print(velocities[velocity_point])\n",
    "#     print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 ms, sys: 0 ns, total: 3.86 ms\n",
      "Wall time: 3.75 ms\n",
      "CPU times: user 28.8 ms, sys: 8.01 ms, total: 36.8 ms\n",
      "Wall time: 1.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/idies/workspace/turb/data05_03/iso8192db_13/iso8192db0013_vel_0.bin',\n",
       " 1687886336,\n",
       " 37,\n",
       " 1610612736)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range for X, Y, and Z grid points are 0 to N-1\n",
    "X = 1053; Y = 100; Z = 1000;\n",
    "# variable of interest, currently set to velocity\n",
    "var = 'vel'\n",
    "# time point\n",
    "timepoint = 0\n",
    "%time iso_data.getFileForPoint(X, Y, Z, var, timepoint)\n",
    "%time iso_data.getFileForPoint_nocache(X, Y, Z, var, timepoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42414568785037976, 0.07669903939428206, 0.7669903939428205)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for trials on  http://turbulence.pha.jhu.edu/webquery/query.aspx\n",
    "# converts the X, Y, and Z points to the domain of [0, 2*pi]\n",
    "dxyz=2*math.pi/8192\n",
    "x=X*dxyz\n",
    "y=Y*dxyz\n",
    "z=Z*dxyz\n",
    "# enter these values in UI\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632\n",
      "CPU times: user 1.63 s, sys: 2.35 ms, total: 1.63 s\n",
      "Wall time: 1.63 s\n",
      "total time = 1.63346 seconds\n"
     ]
    }
   ],
   "source": [
    "# gets velocity for all points inside the user specified box\n",
    "iso_data = IsoCube(cube_num = 8192, cube_dimensions = 3, cube_subtitle = '')\n",
    "\n",
    "var = 'vel'\n",
    "timepoint = 0\n",
    "\n",
    "# user specified box rather than a singular data point\n",
    "x_range = [1000, 1023]\n",
    "y_range = [100, 100]\n",
    "z_range = [1022, 1023]\n",
    "\n",
    "x_range = [0, 511]\n",
    "y_range = [0, 10]\n",
    "z_range = [0, 0]\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "%time iso_data.mapBoxPointsToBytes(x_range, y_range, z_range, var, timepoint, verbose = False)\n",
    "    \n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f'total time = {round(end_time - start_time, 5)} seconds')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare direct access to cutout\n",
    "To get raw data in HDF5 format one can run a job at http://turbulence.idies.jhu.edu/cutout/jobs.\n",
    "Result will be put on scratch. Here an example reading the result of such a job, using the parameters.txt to find the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'isotropic8192',\n",
       " 'filter_width': 1,\n",
       " 'function': 'u',\n",
       " 'output_filename': 'isotropic8192',\n",
       " 'stridet': 1,\n",
       " 'stridex': 1,\n",
       " 'stridey': 1,\n",
       " 'stridez': 1,\n",
       " 'te': 1,\n",
       " 'token': 'edu.jhu.pha.turbulence.testing-201406',\n",
       " 'ts': 1,\n",
       " 'xe': 1010,\n",
       " 'xs': 1000,\n",
       " 'ye': 10,\n",
       " 'ys': 1,\n",
       " 'ze': 10,\n",
       " 'zs': 1}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ran job x in [1000,1010], y and z in [1,10]\n",
    "#folder='/home/idies/workspace/Temporary/gerard/scratch/jobs/__turbcutout__/20211012/20211012094603-148997/'\n",
    "folder = '/home/idies/workspace/Temporary/mschnau1/scratch/jobs/__turbcutout__/20211027/20211027121934-151320/'\n",
    "p=f'{folder}parameters.txt' \n",
    "with open(p,'r') as f:\n",
    "    pars=json.load(f)\n",
    "pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=f'{folder}isotropic8192.h5' \n",
    "h5=h5py.File(f,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 11, 3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5['Velocity_0001'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=h5['xcoor']\n",
    "y=h5['ycoor']\n",
    "z=h5['zcoor']\n",
    "vel=h5['Velocity_0001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.850525  ,  0.42863464,  3.3042493 ], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose an offset in the retrieved cutout\n",
    "dx=3;dy=4;dz=7;\n",
    "v1=vel[dz,dy,dx,:]\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate position in the file\n",
    "X=pars['xs']+dx-1\n",
    "Y=pars['ys']+dy-1  # cutout starts at 1\n",
    "Z=pars['zs']+dz-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.8505249 ,  0.42863464,  3.30424929])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var='vel'\n",
    "timepoint=pars['ts']-1   # in cutout time starts at 1\n",
    "v2=isoData.getISO_Point(X,Y,Z,var,timepoint,verbose=False)\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hope this would be zeros\n",
    "v1-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88515317, 2.20288801, 2.40113282])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v4=isoData.getISO_Point(553,100,1000,var,timepoint,verbose=False)\n",
    "v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(553, 100, 1000): array([0.88515317, 2.20288801, 2.40113282])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(v3)\n",
    "v4-v3[X, Y, Z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
