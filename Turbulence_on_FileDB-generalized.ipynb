{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accessing turbulence isotropic cube files on filedb cluster from sciserver\n",
    "* created volume container (turb) showing all /turb folders on filedb system\n",
    "* access to turbinfo for metadata about these files\n",
    " * requires copying DataPath table\n",
    "* morton curve code pip installed in sciserver container\n",
    "* some special code to take into account 8x8x8 blobs with z-y-x ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: morton-py in /home/idies/miniconda3/envs/py38/lib/python3.8/site-packages (1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install morton-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import math\n",
    "import time\n",
    "import morton\n",
    "#import psutil\n",
    "#import tracemalloc\n",
    "#import struct\n",
    "import numpy as np\n",
    "import SciServer.CasJobs as cj\n",
    "\n",
    "class IsoCube:\n",
    "    def __init__(self, cube_num, cube_dimensions = 3, cube_title = ''):\n",
    "        # cube size.\n",
    "        self.N = cube_num\n",
    "        \n",
    "        # turbulence dataset name, e.g. \"isotropic8192\" or \"isotropic1024fine\".\n",
    "        self.cube_title = cube_title\n",
    "        \n",
    "        # setting up Morton curve.\n",
    "        bits = int(math.log(self.N, 2))\n",
    "        self.mortoncurve = morton.Morton(dimensions = cube_dimensions, bits = bits)\n",
    "        \n",
    "        self.initcache()\n",
    "        \n",
    "    def initcache(self):\n",
    "        # read SQL metadata for all of the turbulence data files into the cache\n",
    "        sql = f\"\"\"\n",
    "        select dbm.ProductionMachineName\n",
    "        , dbm.ProductionDatabaseName\n",
    "        , dbm.minLim, dbm.maxLim\n",
    "        , dbm.minTime, dbm.maxTime\n",
    "        , dp.path\n",
    "        from databasemap dbm\n",
    "           join datapath{str(self.N)} dp\n",
    "             on dp.datasetid=dbm.datasetid\n",
    "           and dp.productionmachinename=dbm.productionmachinename\n",
    "           and dp.ProductionDatabaseName=dbm.ProductionDatabaseName\n",
    "        where dbm.datasetname = '{self.cube_title}'\n",
    "        order by minlim\n",
    "        \"\"\"\n",
    "        df = cj.executeQuery(sql, \"turbinfo\")\n",
    "        \n",
    "        x, y, z = self.mortoncurve.unpack(df['minLim'].values)\n",
    "        df['x_min'] = x\n",
    "        df['y_min'] = y\n",
    "        df['z_min'] = z\n",
    "        \n",
    "        x, y, z = self.mortoncurve.unpack(df['maxLim'].values)\n",
    "        df['x_max'] = x\n",
    "        df['y_max'] = y \n",
    "        df['z_max'] = z\n",
    "        \n",
    "        self.cache = df\n",
    "    \n",
    "    # defines some helper functions, all hardcoded (double-check this when other datasets are available)\n",
    "    def parseCornerPoints(self, x_min, x_max, y_min, y_max, z_min, z_max):\n",
    "        # only points 1, 2, 4, and 5 are required for finding the correct sub-boxes.\n",
    "        # corner 1 is the bottom left back side origin point.\n",
    "        # corner 2 is the bottom right back side corner point (same as corner 1 except at the maximum x-position).\n",
    "        # corner 4 is the bottom left front side corner point (same as corner 1 except at the maximum y-positon).\n",
    "        # corner 5 is the top left back corner point (same as corner 1 except at the maximum z-positon).\n",
    "        # corners 2, 3, and 4 travel around the bottom plane of the box clockwise from corner 1.\n",
    "        # corners 6, 7, and 8 travel around the top plane of the box clockwise from corner 5.\n",
    "        c1 = (x_min, y_min, z_min)\n",
    "        c2 = (x_max, y_min, z_min)\n",
    "        #c3 = (x_max, y_max, z_min)\n",
    "        c4 = (x_min, y_max, z_min)\n",
    "        c5 = (x_min, y_min, z_max)\n",
    "        #c6 = (x_max, y_min, z_max)\n",
    "        #c7 = (x_max, y_max, z_max)\n",
    "        #c8 = (x_min, y_max, z_max)\n",
    "        \n",
    "        corner_points = (c1, c2, c4, c5)\n",
    "        \n",
    "        return corner_points\n",
    "        \n",
    "    def getFilesForCornerPoints(self, x_range, y_range, z_range, var, timepoint):\n",
    "        # define the corner points.\n",
    "        x_min = x_range[0]; x_max = x_range[1];\n",
    "        y_min = y_range[0]; y_max = y_range[1];\n",
    "        z_min = z_range[0]; z_max = z_range[1];\n",
    "        \n",
    "        # retrieve the corner points.\n",
    "        c_points = self.parseCornerPoints(x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "        \n",
    "        database_files = []\n",
    "        \n",
    "        # only points 1, 2, 4, and 5 are required for finding the correct sub-boxes.\n",
    "        c1_info = self.getFileForPoint(c_points[0][0], c_points[0][1], c_points[0][2], var, timepoint)\n",
    "        c1_file = c1_info[0]\n",
    "        database_files.append(c1_file)\n",
    "        \n",
    "        c2_info = self.getFileForPoint(c_points[1][0], c_points[1][1], c_points[1][2], var, timepoint)\n",
    "        c2_file = c2_info[0]\n",
    "        database_files.append(c2_file)\n",
    "        \n",
    "        c4_info = self.getFileForPoint(c_points[2][0], c_points[2][1], c_points[2][2], var, timepoint)\n",
    "        c4_file = c4_info[0]\n",
    "        database_files.append(c4_file)\n",
    "        \n",
    "        c5_info = self.getFileForPoint(c_points[3][0], c_points[3][1], c_points[3][2], var, timepoint)\n",
    "        c5_file = c5_info[0]\n",
    "        database_files.append(c5_file)\n",
    "        \n",
    "        return database_files\n",
    "    \n",
    "    def findSubBoxEndPoint(self, axis_range, datapoint, axis_position, db_file_comparison, var, timepoint):\n",
    "        # placeholder end point value. \n",
    "        end_point = -1\n",
    "        # if the difference between the axis range end points is <= to this value, then the end_point\n",
    "        # has been found.\n",
    "        axis_range_difference = 2\n",
    "        \n",
    "        end_point_found = False\n",
    "        while not end_point_found:\n",
    "            mid_point = math.floor((axis_range[0] + axis_range[1]) / 2)\n",
    "            \n",
    "            # stops recursively shrinking the box once the difference between the two end points is <= axis_range_difference.\n",
    "            if (axis_range[1] - axis_range[0]) <= axis_range_difference:\n",
    "                end_point_found = True\n",
    "            \n",
    "            # updates the datapoint to the new mid point.\n",
    "            datapoint[axis_position] = mid_point\n",
    "            \n",
    "            # gets the db file for the new datapoint.\n",
    "            datapoint_info = self.getFileForPoint(datapoint[0], datapoint[1], datapoint[2], var, timepoint)\n",
    "            datapoint_file = datapoint_info[0]\n",
    "            \n",
    "            # compares the db file for datapoint to the origin point.\n",
    "            if datapoint_file == db_file_comparison:\n",
    "                end_point = mid_point\n",
    "                axis_range[0] = mid_point\n",
    "            else:\n",
    "                end_point = mid_point - 1\n",
    "                axis_range[1] = mid_point\n",
    "            \n",
    "            # used for checking that there were no redundant calculations\n",
    "            #print(f'midpoint = {mid_point}')\n",
    "            #print(f'endpoint = {end_point}')\n",
    "            #print('-')\n",
    "                \n",
    "        return end_point\n",
    "    \n",
    "    def recursiveSingleDatabaseFileSubBoxes(self, box, var, timepoint, single_file_boxes):\n",
    "        db_files = self.getFilesForCornerPoints(box[0], box[1], box[2], var, timepoint)\n",
    "        num_db_files = len(set(db_files))\n",
    "\n",
    "        if num_db_files == 1:\n",
    "            unique_db_file = list(set(db_files))[0]\n",
    "            if unique_db_file in single_file_boxes:\n",
    "                raise Exception(f'{unique_db_file} is already in single_file_boxes')\n",
    "            \n",
    "            # stores the minLim of the box for use later when reading in the data.\n",
    "            box_info = self.getFileForPoint(box[0][0], box[1][0], box[2][0], var, timepoint)\n",
    "            box_minLim = box_info[3]\n",
    "            \n",
    "            single_file_boxes[unique_db_file] = (box, box_minLim)\n",
    "            \n",
    "            return\n",
    "        elif db_files[0] != db_files[1]:\n",
    "            # this means that the x_range was sufficiently large such that all of the points were\n",
    "            # not contained in a singular database file.  i.e. the database files were different for\n",
    "            # corners 1 and 2.  the data x_range will now be recursively split in half to find the first databse file endpoint\n",
    "            # along this axis.\n",
    "\n",
    "            # this value is specified as 0 because the x-axis index is 0.  this is used for determing which \n",
    "            # point (X, Y, or Z) the midpoint is going to be tested for.  in this case, this section of code\n",
    "            # is adjusting only the x-axis.\n",
    "            axis_position = 0\n",
    "            # stores the c1 corner point (X, Y, Z) of the box to be used for finding the first box end point\n",
    "            # when shrinking the x-axis into sub-boxes.\n",
    "            datapoint = [box[0][0], box[1][0], box[2][0]]\n",
    "            # which axis is sub-divided, in this case it is the x-axis.\n",
    "            axis_range = list(box[0])\n",
    "            # determine where the end x-axis point is for the first sub-box.\n",
    "            first_box_end_point = self.findSubBoxEndPoint(axis_range, datapoint, axis_position, db_files[0], \\\n",
    "                                                                       var, timepoint)\n",
    "\n",
    "            first_sub_box = [[box[0][0], first_box_end_point], box[1], box[2]]\n",
    "            second_sub_box = [[first_box_end_point + 1, box[0][1]], box[1], box[2]]\n",
    "            \n",
    "            sub_boxes = []\n",
    "            sub_boxes.append(first_sub_box)\n",
    "            sub_boxes.append(second_sub_box)\n",
    "            \n",
    "            for sub_box in sub_boxes:\n",
    "                self.recursiveSingleDatabaseFileSubBoxes(sub_box, var, timepoint, single_file_boxes)\n",
    "        elif db_files[0] != db_files[2]:\n",
    "            # this means that the y_range was sufficiently large such that all of the points were\n",
    "            # not contained in a singular database file.  i.e. the database files were different for\n",
    "            # corners 1 and 4.  the data y_range will now be recursively split in half to find the first databse file endpoint\n",
    "            # along this axis.\n",
    "\n",
    "            # this value is specified as 1 because the y-axis index is 1.  this is used for determing which \n",
    "            # point (X, Y, or Z) the midpoint is going to be tested for.  in this case, this section of code\n",
    "            # is adjusting only the y-axis.\n",
    "            axis_position = 1\n",
    "            # stores the c1 corner point (X, Y, Z) of the box to be used for finding the first box end point \n",
    "            # when shrinking the y-axis into sub-boxes.\n",
    "            datapoint = [box[0][0], box[1][0], box[2][0]]\n",
    "            # which axis is sub-divided, in this case it is the y-axis.\n",
    "            axis_range = list(box[1])\n",
    "            # determine where the end y-axis point is for the first sub-box.\n",
    "            first_box_end_point = self.findSubBoxEndPoint(axis_range, datapoint, axis_position, db_files[0], \\\n",
    "                                                                       var, timepoint)\n",
    "\n",
    "            first_sub_box = [box[0], [box[1][0], first_box_end_point], box[2]]\n",
    "            second_sub_box = [box[0], [first_box_end_point + 1, box[1][1]], box[2]]\n",
    "\n",
    "            sub_boxes = []\n",
    "            sub_boxes.append(first_sub_box)\n",
    "            sub_boxes.append(second_sub_box)\n",
    "            \n",
    "            for sub_box in sub_boxes:\n",
    "                self.recursiveSingleDatabaseFileSubBoxes(sub_box, var, timepoint, single_file_boxes)\n",
    "        elif db_files[0] != db_files[3]:\n",
    "            # this means that the z_range was sufficiently large such that all of the points were\n",
    "            # not contained in a singular database file.  i.e. the database files were different for\n",
    "            # corners 1 and 5.  the data z_range will now be recursively split in half to find the first databse file endpoint\n",
    "            # along this axis.\n",
    "\n",
    "            # this value is specified as 2 because the z-axis index is 2.  this is used for determing which \n",
    "            # point (X, Y, or Z) the midpoint is going to be tested for.  in this case, this section of code\n",
    "            # is adjusting only the z-axis.\n",
    "            axis_position = 2\n",
    "            # stores the c1 corner point (X, Y, Z) of the box to be used for finding the first box end point \n",
    "            # when shrinking the z-axis into sub-boxes.\n",
    "            datapoint = [box[0][0], box[1][0], box[2][0]]\n",
    "            # which axis is sub-divided, in this case it is the z-axis.\n",
    "            axis_range = list(box[2])\n",
    "            # determine where the end z-axis point is for the first sub-box.\n",
    "            first_box_end_point = self.findSubBoxEndPoint(axis_range, datapoint, axis_position, db_files[0], \\\n",
    "                                                          var, timepoint)\n",
    "\n",
    "            first_sub_box = [box[0], box[1], [box[2][0], first_box_end_point]]\n",
    "            second_sub_box = [box[0], box[1], [first_box_end_point + 1, box[2][1]]]\n",
    "            \n",
    "            sub_boxes = []\n",
    "            sub_boxes.append(first_sub_box)\n",
    "            sub_boxes.append(second_sub_box)\n",
    "            \n",
    "            for sub_box in sub_boxes:\n",
    "                self.recursiveSingleDatabaseFileSubBoxes(sub_box, var, timepoint, single_file_boxes)\n",
    "    \n",
    "    def identifySingleDatabaseFileSubBoxes(self, x_range, y_range, z_range, var, timepoint):\n",
    "        # initially assumes the user specified box contains points in different files. the boxes will be split up until all the points\n",
    "        # in each box are from a single database file.\n",
    "        box = [x_range, y_range, z_range]\n",
    "        single_file_boxes = {}\n",
    "        self.recursiveSingleDatabaseFileSubBoxes(box, var, timepoint, single_file_boxes)\n",
    "            \n",
    "        return single_file_boxes\n",
    "    \n",
    "    def boxesContained(self, sub_box, user_box):\n",
    "        contained = False\n",
    "        # checks if the sub-divided box is fully contained within the user-specified box.\n",
    "        if (sub_box[0][0] >= user_box[0][0] and sub_box[0][1] <= user_box[0][1]) and \\\n",
    "            (sub_box[1][0] >= user_box[1][0] and sub_box[1][1] <= user_box[1][1]) and \\\n",
    "            (sub_box[2][0] >= user_box[2][0] and sub_box[2][1] <= user_box[2][1]):\n",
    "            contained = True\n",
    "        \n",
    "        return contained\n",
    "    \n",
    "    def boxesOverlap(self, sub_box, user_box):\n",
    "        overlap = False\n",
    "        # checks if the sub-divided box and the user-specified box overlap on all 3 axes\n",
    "        if (sub_box[0][0] <= user_box[0][1] and user_box[0][0] <= sub_box[0][1]) and \\\n",
    "            (sub_box[1][0] <= user_box[1][1] and user_box[1][0] <= sub_box[1][1]) and \\\n",
    "            (sub_box[2][0] <= user_box[2][1] and user_box[2][0] <= sub_box[2][1]):\n",
    "            overlap = True\n",
    "            \n",
    "        return overlap\n",
    "    \n",
    "    def determineMinOverlapPoint(self, voxel, user_box, axis):\n",
    "        min_point = None\n",
    "        \n",
    "        # checks if the user-specified box minimum value along the given axis is <= the voxel minimum value along the same axis.  if so, then the minimum\n",
    "        # value is stored as voxel minimum value.  otherwise, the minimum value is stored as the user-specified box minimum value.\n",
    "        if user_box[axis][0] <= voxel[axis][0]:\n",
    "            min_point = voxel[axis][0]\n",
    "        else:\n",
    "            min_point = user_box[axis][0]\n",
    "            \n",
    "        return min_point\n",
    "    \n",
    "    def determineMaxOverlapPoint(self, voxel, user_box, axis):\n",
    "        max_point = None\n",
    "        \n",
    "        # checks if the user-specified box maximum value along the given axis is >= the voxel maximum value along the same axis.  if so, then the maximum\n",
    "        # value is stored as voxel maximum value.  otherwise, the maximum value is stored as the user-specified box maximum value.\n",
    "        if user_box[axis][1] >= voxel[axis][1]:\n",
    "            max_point = voxel[axis][1]\n",
    "        else:\n",
    "            max_point = user_box[axis][1]\n",
    "            \n",
    "        return max_point\n",
    "    \n",
    "    def voxelRangesInUserBox(self, voxel, user_box):\n",
    "        # determine the minimum and maximum values of the overlap, along each axis, between voxel and the user-specified box for a partially overlapped voxel.\n",
    "        # axis 0 corresponds to the x-axis.\n",
    "        # axis 1 corresponds to the y-axis.\n",
    "        # axis 2 corresponds to the z-axis.\n",
    "        voxel_x_min = self.determineMinOverlapPoint(voxel, user_box, axis = 0)\n",
    "        voxel_x_max = self.determineMaxOverlapPoint(voxel, user_box, axis = 0)\n",
    "        \n",
    "        voxel_y_min = self.determineMinOverlapPoint(voxel, user_box, axis = 1)\n",
    "        voxel_y_max = self.determineMaxOverlapPoint(voxel, user_box, axis = 1)\n",
    "        \n",
    "        voxel_z_min = self.determineMinOverlapPoint(voxel, user_box, axis = 2)\n",
    "        voxel_z_max = self.determineMaxOverlapPoint(voxel, user_box, axis = 2)\n",
    "        \n",
    "        voxel_data = [[voxel_x_min, voxel_x_max], [voxel_y_min, voxel_y_max], [voxel_z_min, voxel_z_max]]\n",
    "        \n",
    "        return voxel_data\n",
    "        \n",
    "    def recursiveSubBoxesInFile(self, box, user_db_box, morton_voxels_to_read, voxel_side_length = 8):\n",
    "        # recursively sub-divides the database file cube until the entire user-specified box is mapped by morton cubes.\n",
    "        box_x_range = box[0]\n",
    "        box_y_range = box[1]\n",
    "        box_z_range = box[2]\n",
    "        \n",
    "        # only need to check one axes since each sub-box is a cube. this value will be compared to voxel_side_length to limit the recursive\n",
    "        # shrinking algorithm.\n",
    "        sub_box_axes_length = box_x_range[1] - box_x_range[0] + 1\n",
    "        \n",
    "        # checks if the sub-box corner points are all inside the portion of the user-specified box in the database file.\n",
    "        box_fully_contained = self.boxesContained(box, user_db_box)\n",
    "        box_partially_contained = self.boxesOverlap(box, user_db_box)\n",
    "        # recursively shrinks to voxel-sized boxes (8 x 8 x 8), and stores all of the necessary information regarding these boxes\n",
    "        # that will be used when reading in data from the database file.\n",
    "        if sub_box_axes_length == voxel_side_length:\n",
    "            if box_fully_contained or box_partially_contained:\n",
    "                # converts the box (X, Y, Z) minimum and maximum points to morton indices for the database file.\n",
    "                morton_index_min = self.mortoncurve.pack(box[0][0], box[1][0], box[2][0])\n",
    "                morton_index_max = self.mortoncurve.pack(box[0][1], box[1][1], box[2][1])\n",
    "                \n",
    "                # stores the x-, y-, an z- ranges of the user-specified box that the voxel is contained in.\n",
    "                voxel_ranges = []\n",
    "                if box_fully_contained:\n",
    "                    # sub-box is fully contained within the user-specified box.\n",
    "                    voxel_ranges = [box_x_range, box_y_range, box_z_range]\n",
    "                else:\n",
    "                    # sub-box is partially contained within the user-specified box.\n",
    "                    voxel_ranges = list(self.voxelRangesInUserBox(box, user_db_box))\n",
    "                \n",
    "                # stores the voxel information so that the data values can be mapped back to (X, Y, Z) points efficiently. specifically,\n",
    "                # the cornercode of the box, the minimum and maximum morton indices of the box, and the box x-axis, y-axis, and z-axis ranges are stored.\n",
    "                # the cornercode and offset correspond to the sub-box minimum axes point (X_min, Y_min, Z_min) - this should mean the offset is always 0.\n",
    "                voxel_data = self.getOffset(box[0][0], box[1][0], box[2][0])\n",
    "                voxel_cornercode = voxel_data[0]\n",
    "                voxel_offset = voxel_data[1]\n",
    "                voxel_info = [voxel_cornercode, voxel_offset, voxel_ranges]\n",
    "                \n",
    "                # stores the morton indices for reading from the database file efficiently and voxel info for parsing out the voxel information.\n",
    "                if morton_voxels_to_read == list():\n",
    "                    morton_voxel_info = [[morton_index_min, morton_index_max], voxel_info]\n",
    "                    morton_voxels_to_read.append(morton_voxel_info)\n",
    "                else:\n",
    "                    # check if the most recent sub-box maximum is 1 index less than the new sub-box minimum.  if so, then \n",
    "                    # extend the range of the previous sub-box morton maximum to stitch these two boxes together. also, append\n",
    "                    # the new voxel info so that the voxel information can be parsed out since the morton index range now spans\n",
    "                    # more than one voxel.\n",
    "                    if morton_voxels_to_read[-1][0][1] == (morton_index_min - 1):\n",
    "                        morton_voxels_to_read[-1][0][1] = morton_index_max\n",
    "                        morton_voxels_to_read[-1].append(voxel_info)\n",
    "                    else:\n",
    "                        # start a new morton sequence that will be read in separately.\n",
    "                        morton_voxel_info = [[morton_index_min, morton_index_max], voxel_info]\n",
    "                        morton_voxels_to_read.append(morton_voxel_info)\n",
    "\n",
    "            return\n",
    "        else:\n",
    "            if box_partially_contained:\n",
    "                # sub-divide the box into 8 sub-cubes (divide the x-, y-, and z- axes in half) and recursively check each box if \n",
    "                # it is inside the user-specified box, if necessary.\n",
    "                box_x_range_midpoint = math.floor((box_x_range[0] + box_x_range[1]) / 2)\n",
    "                box_y_range_midpoint = math.floor((box_y_range[0] + box_y_range[1]) / 2)\n",
    "                box_z_range_midpoint = math.floor((box_z_range[0] + box_z_range[1]) / 2)\n",
    "                \n",
    "                # ordering sub-boxes 1-8 below in this order maintains the morton-curve index structure, such that \n",
    "                # the minimum (X, Y, Z) morton index for a new box only needs to be compared to the last \n",
    "                # sub-boxes' maximum (X, Y, Z) morton index to see if they can be stitched together.\n",
    "                \n",
    "                # new_sub_box_1 is the sub-box bounded by [x_min, x_midpoint], [y_min, y_midpoint], and [z_min, z_midpoint]\n",
    "                # new_sub_box_2 is the sub-box bounded by [x_midpoint + 1, x_max], [y_min, y_midpoint], and [z_min, z_midpoint]\n",
    "                # new_sub_box_3 is the sub-box bounded by [x_min, x_midpoint], [y_midpoint + 1, y_max], and [z_min, z_midpoint]\n",
    "                # new_sub_box_4 is the sub-box bounded by [x_midpoint + 1, x_max], [y_midpoint + 1, y_max], and [z_min, z_midpoint]\n",
    "                new_sub_box_1 = [[box_x_range[0], box_x_range_midpoint], [box_y_range[0], box_y_range_midpoint], [box_z_range[0], box_z_range_midpoint]]\n",
    "                new_sub_box_2 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range[0], box_y_range_midpoint], [box_z_range[0], box_z_range_midpoint]]\n",
    "                new_sub_box_3 = [[box_x_range[0], box_x_range_midpoint], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range[0], box_z_range_midpoint]]\n",
    "                new_sub_box_4 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range[0], box_z_range_midpoint]]\n",
    "                \n",
    "                # new_sub_box_5 is the sub-box bounded by [x_min, x_midpoint], [y_min, y_midpoint], and [z_midpoint + 1, z_max]\n",
    "                # new_sub_box_6 is the sub-box bounded by [x_midpoint + 1, x_max], [y_min, y_midpoint], and [z_midpoint + 1, z_max]\n",
    "                # new_sub_box_7 is the sub-box bounded by [x_min, x_midpoint], [y_midpoint + 1, y_max], and [z_midpoint + 1, z_max]\n",
    "                # new_sub_box_8 is the sub-box bounded by [x_midpoint + 1, x_max], [y_midpoint + 1, y_max], and [z_midpoint + 1, z_max]\n",
    "                new_sub_box_5 = [[box_x_range[0], box_x_range_midpoint], [box_y_range[0], box_y_range_midpoint], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "                new_sub_box_6 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range[0], box_y_range_midpoint], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "                new_sub_box_7 = [[box_x_range[0], box_x_range_midpoint], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "                new_sub_box_8 = [[box_x_range_midpoint + 1, box_x_range[1]], [box_y_range_midpoint + 1, box_y_range[1]], [box_z_range_midpoint + 1, box_z_range[1]]]\n",
    "\n",
    "                new_sub_boxes = []\n",
    "                new_sub_boxes.append(new_sub_box_1)\n",
    "                new_sub_boxes.append(new_sub_box_2)\n",
    "                new_sub_boxes.append(new_sub_box_3)\n",
    "                new_sub_boxes.append(new_sub_box_4)\n",
    "                new_sub_boxes.append(new_sub_box_5)\n",
    "                new_sub_boxes.append(new_sub_box_6)\n",
    "                new_sub_boxes.append(new_sub_box_7)\n",
    "                new_sub_boxes.append(new_sub_box_8)\n",
    "                    \n",
    "                for new_sub_box in new_sub_boxes:\n",
    "                    # checks if a sub-box is at least partially contained inside the user-specified box. if so, then the sub-box will \n",
    "                    # be recursively searched until an entire sub-box is inside the user-specified box.\n",
    "                    new_sub_box_partially_contained = self.boxesOverlap(new_sub_box, user_db_box)\n",
    "\n",
    "                    if new_sub_box_partially_contained:\n",
    "                        self.recursiveSubBoxesInFile(new_sub_box, user_db_box, morton_voxels_to_read, voxel_side_length)\n",
    "        return\n",
    "        \n",
    "    def identifySubBoxesInFile(self, user_db_box, var, timepoint, voxel_side_length = 8):\n",
    "        # initially assumes the user-specified box in the file is not the entire box representing the file. the database file box will \n",
    "        # be sub-divided into morton cubes until the user-specified box is completely mapped by all of these sub-cubes.\n",
    "        user_db_box_x_range = user_db_box[0]\n",
    "        user_db_box_y_range = user_db_box[1]\n",
    "        user_db_box_z_range = user_db_box[2]\n",
    "        \n",
    "        user_db_box_x_min = user_db_box_x_range[0]\n",
    "        user_db_box_y_min = user_db_box_y_range[0]\n",
    "        user_db_box_z_min = user_db_box_z_range[0]\n",
    "        \n",
    "        # retrieve the morton index limits (minLim, maxLim) of the cube representing the whole database file\n",
    "        f, cornercode, offset, minLim, maxLim = self.getFileForPoint(user_db_box_x_min, user_db_box_y_min, user_db_box_z_min, var, timepoint)\n",
    "        minLim_xyz = self.mortoncurve.unpack(minLim)\n",
    "        maxLim_xyz = self.mortoncurve.unpack(maxLim)\n",
    "        \n",
    "        # get the box for the entire database file so that it can be recursively broken down into cubes\n",
    "        db_box = [[minLim_xyz[0], maxLim_xyz[0]], [minLim_xyz[1], maxLim_xyz[1]], [minLim_xyz[2], maxLim_xyz[2]]]\n",
    "        \n",
    "        # these are the constituent file sub-cubes that make up the part of the user-specified box in the database file\n",
    "        morton_voxels_to_read = []\n",
    "        self.recursiveSubBoxesInFile(db_box, user_db_box, morton_voxels_to_read, voxel_side_length)\n",
    "\n",
    "        return morton_voxels_to_read\n",
    "        \n",
    "    def getVelocitiesForAllPoints(self, x_range, y_range, z_range, min_step = 1):\n",
    "        # manually retrieves the velocities for all points inside the box. this is computationally expensive and not efficient, and \n",
    "        # this function is deprecated.\n",
    "        x_min = x_range[0]; x_max = x_range[1];\n",
    "        y_min = y_range[0]; y_max = y_range[1];\n",
    "        z_min = z_range[0]; z_max = z_range[1];\n",
    "        \n",
    "        current_x_max = x_max\n",
    "        current_y_max = y_max\n",
    "        current_z_max = z_max\n",
    "        \n",
    "        velocity_map = {}\n",
    "        velocity_data = np.array([-1, -1, -1])\n",
    "        for x_point in np.arange(x_min, x_max + 1, min_step):\n",
    "            for y_point in np.arange(y_min, y_max + 1, min_step):\n",
    "                for z_point in np.arange(z_min, z_max + 1, min_step):\n",
    "                    velocity_data = self.getISO_Point(x_point, y_point, z_point, var = 'vel', timepoint = 0, verbose = False)\n",
    "                    \n",
    "                    velocity_map[(x_point, y_point, z_point)] = velocity_data\n",
    "                    #print(x_point)\n",
    "                    #print(cornercode, offset)\n",
    "        \n",
    "        return velocity_map\n",
    "        \n",
    "    def getOffset(self, X, Y, Z):\n",
    "        \"\"\"\n",
    "        TODO is this code correct for velocity as well?  YES\n",
    "        \"\"\"\n",
    "        # morton curve index corresponding to the user specified X, Y, and Z values\n",
    "        code = self.mortoncurve.pack(X, Y, Z)\n",
    "        # always looking at an 8 x 8 x 8 box around the grid point, so the shift is always 9 bits to determine \n",
    "        # the bottom left corner of the box. the cornercode (bottom left corner of the 8 x 8 x 8 box) is always \n",
    "        # in the same file as the user-specified grid point.\n",
    "        # equivalent to 512 * (math.floor(code / 512))\n",
    "        cornercode = (code >> 9) << 9\n",
    "        corner = np.array(self.mortoncurve.unpack(cornercode))\n",
    "        # calculates the offset between the grid point and corner of the box and converts it to a 4-byte float.\n",
    "        offset = np.sum((np.array([X, Y, Z]) - corner) * np.array([1, 8, 64]))\n",
    "        \n",
    "        return cornercode, offset\n",
    "    \n",
    "    def getFileForPoint(self, X, Y, Z, var = 'pr', timepoint = 0):\n",
    "        \"\"\"\n",
    "        querying the cached SQL metadata for the file for the user specified grid point\n",
    "        \"\"\"\n",
    "        cornercode, offset = self.getOffset(X, Y, Z)\n",
    "        t = self.cache[(self.cache['minLim'] <= cornercode) & (self.cache['maxLim'] >= cornercode)]\n",
    "        t = t.iloc[0]\n",
    "        dataN = t.path.split(\"/\")\n",
    "        f = f'/home/idies/workspace/turb/data{t.ProductionMachineName[-2:]}_{dataN[2][-2:]}/{dataN[-1]}/{t.ProductionDatabaseName}_{var}_{timepoint}.bin'\n",
    "        return f, cornercode, offset, t.minLim, t.maxLim\n",
    "        \n",
    "    def getISO_Points(self, db_file, morton_voxels_to_read, output_data, \\\n",
    "                      db_minLim, x_min, y_min, z_min, \\\n",
    "                      num_values_per_datapoint = 1, bytes_per_datapoint = 4, voxel_side_length = 8, verbose = False):\n",
    "        \"\"\"\n",
    "        retrieve the values for the specified var(iable) in the user-specified box and at the specified timepoint.\n",
    "        \"\"\"\n",
    "        # used to check the memory usage so that it could be minimized.\n",
    "        #process = psutil.Process(os.getpid())\n",
    "        #print(f'memory usage 1 (gigabytes) = {(process.memory_info().rss) / (1024**3)}')  # in bytes \n",
    "\n",
    "        # volume of the voxel cube.\n",
    "        voxel_cube_size = voxel_side_length**3\n",
    "        \n",
    "        # iterates over the groups of morton adjacent voxels to minimize the number I/O operations when reading the data.\n",
    "        for morton_data in morton_voxels_to_read:\n",
    "            # the continuous range of morton indices compiled from adjacent voxels that can be read in from the file at the same time.\n",
    "            morton_index_range = morton_data[0]\n",
    "            # the voxels that will be parsed out from the data that is read in. the voxels need to parsed separately because the data is sequentially\n",
    "            # ordered within a voxel as opposed to morton ordered outside a voxel.\n",
    "            voxel_data = morton_data[1:]\n",
    "            \n",
    "            # morton_index_min is equivalent to \"cornercode + offset\" because morton_index_min is defined as the corner of a voxel.\n",
    "            morton_index_min = morton_index_range[0]\n",
    "            morton_index_max = morton_index_range[1]\n",
    "            morton_index_diff = (morton_index_max - morton_index_min) + 1\n",
    "            \n",
    "            # the point to seek to in order to start reading the file for this morton index range.\n",
    "            seek_distance = num_values_per_datapoint * bytes_per_datapoint * (morton_index_min - db_minLim)\n",
    "            # number of bytes to read in from the database file.\n",
    "            read_length = num_values_per_datapoint * bytes_per_datapoint * morton_index_diff\n",
    "            \n",
    "            # read the data. this method is deprecated because it is slow.\n",
    "            #with open(db_file, 'rb') as b:\n",
    "            #    b.seek(seek_distance)\n",
    "            #    xraw = b.read(read_length)\n",
    "            #\n",
    "            # unpack the data as 4-byte floats.\n",
    "            #l = struct.unpack('f' * num_values_per_datapoint * morton_index_diff, xraw)\n",
    "            \n",
    "            # used to check the memory usage so that it could be minimized.\n",
    "            #print(f'memory usage 1a (gigabytes) = {(process.memory_info().rss) / (1024**3)}')  # in bytes \n",
    "            \n",
    "            # read the data efficiently.\n",
    "            l = np.fromfile(db_file, dtype = 'f', count = read_length, offset = seek_distance)\n",
    "            l = l[np.arange(0, l.size - num_values_per_datapoint + 1, num_values_per_datapoint)[:, None] + np.arange(num_values_per_datapoint)]\n",
    "            \n",
    "            # used to check the memory usage so that it could be minimized.\n",
    "            #print(f'memory usage 1b (gigabytes) = {(process.memory_info().rss) / (1024**3)}')  # in bytes \n",
    "            \n",
    "            # iterate over each voxel in voxel_data.\n",
    "            for voxel_count, voxel_info in enumerate(voxel_data):\n",
    "                # retrieve the x-, y-, and z-ranges for the voxel. these ranges are already adjusted if the voxel was only partially contained\n",
    "                # inside the user-specified box.\n",
    "                voxel_ranges = voxel_info[2]\n",
    "                \n",
    "                # voxel axes ranges.\n",
    "                voxel_x_range = voxel_ranges[0]\n",
    "                voxel_y_range = voxel_ranges[1]\n",
    "                voxel_z_range = voxel_ranges[2]\n",
    "                \n",
    "                # pull out the data that corresponds to this voxel.\n",
    "                sub_l_array = l[voxel_count * voxel_cube_size : (voxel_count + 1) * voxel_cube_size]\n",
    "                \n",
    "                # reshape the sub_l array into a voxel matrix.\n",
    "                sub_l_array = sub_l_array.reshape(voxel_side_length, voxel_side_length, voxel_side_length, num_values_per_datapoint)\n",
    "                # swap the x- and z- axes to maintain the correct structure.\n",
    "                sub_l_array = np.swapaxes(sub_l_array, 0, 2)\n",
    "                # remove parts of the voxel that are outside of the user-specified box.\n",
    "                sub_l_array = sub_l_array[voxel_x_range[0] % voxel_side_length : (voxel_x_range[1] % voxel_side_length) + 1, \\\n",
    "                                          voxel_y_range[0] % voxel_side_length : (voxel_y_range[1] % voxel_side_length) + 1, \\\n",
    "                                          voxel_z_range[0] % voxel_side_length : (voxel_z_range[1] % voxel_side_length) + 1]\n",
    "                \n",
    "                # insert sub_l_array into output_data.\n",
    "                output_data[voxel_x_range[0] - x_min : voxel_x_range[1] - x_min + 1, \\\n",
    "                            voxel_y_range[0] - y_min : voxel_y_range[1] - y_min + 1, \\\n",
    "                            voxel_z_range[0] - z_min : voxel_z_range[1] - z_min + 1] = np.array(sub_l_array)\n",
    "                \n",
    "                # clear sub_l_array to free up memory.\n",
    "                sub_l_array = None\n",
    "                \n",
    "            # clear l to free up memory.\n",
    "            l = None\n",
    "        \n",
    "        # used to check the memory usage so that it could be minimized.\n",
    "        #print(f'memory usage 2 (gigabytes) = {(process.memory_info().rss) / (1024**3)}')  # in bytes \n",
    "            \n",
    "    def getISO_Point_original(self, X, Y, Z, var = 'pr', timepoint = 0, verbose = False):\n",
    "        \"\"\"\n",
    "        find the value for the specified var(iable) at the specified point XYZ and specified time.\n",
    "        Position is assumed to be a point of the grid, i.e. should be integers, and time should be an integer between 0 and 5.\n",
    "        \"\"\"\n",
    "        f, cornercode, offset, minLim, maxLim = self.getFileForPoint(X, Y, Z, var, timepoint)\n",
    "        if verbose:\n",
    "            print(f'filename : {f}')\n",
    "            print(f'cornercode : {cornercode}')\n",
    "            print(f'corner : {np.array(self.mortoncurve.unpack(cornercode))}')\n",
    "            print(f'offset : {offset}')\n",
    "            print(f'minLim : {minLim}')\n",
    "            print(f'maxLim : {maxLim}')\n",
    "            #print(f, cornercode, offset, minLim, maxLim)\n",
    "        \n",
    "        N = 1\n",
    "        if var == 'vel':\n",
    "            N = 3\n",
    "        \n",
    "        with open(f, 'rb') as b:\n",
    "            b.seek(N * 4 * (cornercode + offset - minLim))\n",
    "            xraw = b.read(4 * N)\n",
    "        \n",
    "        l = struct.unpack('f' * N, xraw)\n",
    "        \n",
    "        return l\n",
    "    \n",
    "    def writeOutputMatrixToHDF5(self, output_data, output_path, output_filename, dataset_name):\n",
    "        # write output_data to a hdf5 file.\n",
    "        with h5py.File(output_path + output_filename + '.h5', 'w') as h5f:\n",
    "            h5f.create_dataset(dataset_name, data = output_data)\n",
    "    \n",
    "\"\"\"\n",
    "driver functions for processing the data and retrieving the data values for all points inside of a user-specified box.\n",
    "\"\"\"\n",
    "def retrieveDataForPoint(X, Y, Z, output_data, x_range, y_range, z_range):\n",
    "    # finds the indices corresponding the to the (X, Y, Z) datapoint that the user is asking for and returns the stored data.\n",
    "    # minimum values along each axis for the user-specified box.\n",
    "    x_min = x_range[0]\n",
    "    y_min = y_range[0]\n",
    "    z_min = z_range[0]\n",
    "\n",
    "    # maximum values along each axis for the user-specified box.\n",
    "    x_max = x_range[1]\n",
    "    y_max = y_range[1]\n",
    "    z_max = z_range[1]\n",
    "\n",
    "    # checks if the X, Y, and Z datapoints are inside of the user-specified box that data was retrieved for.\n",
    "    if not (x_min <= X <= x_max):\n",
    "        raise IndexError(f'X datapoint, {X}, must be in the range of [{x_min}, {x_max}]')\n",
    "\n",
    "    if not (y_min <= Y <= y_max):\n",
    "        raise IndexError(f'Y datapoint, {Y}, must be in the range of [{y_min}, {y_max}]')\n",
    "\n",
    "    if not (z_min <= Z <= z_max):\n",
    "        raise IndexError(f'Z datapoint, {Z}, must be in the range of [{z_min}, {z_max}]')\n",
    "\n",
    "    # converts the X, Y, and Z datapoints to their corresponding indices in the output_data array.\n",
    "    x_index = X - x_min\n",
    "    y_index = Y - y_min\n",
    "    z_index = Z - z_min\n",
    "\n",
    "    # retrieves the values stored in the output_data array for the (X, Y, Z) datapoint.\n",
    "    data_value = output_data[x_index][y_index][z_index]\n",
    "\n",
    "    return data_value\n",
    "    \n",
    "def processData(cube_num, cube_dimensions, cube_title, output_path, x_range, y_range, z_range, var, timepoint):\n",
    "    # calculate how much time it takes to run the code.\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # checking the memory usage of the program.\n",
    "    # starting the tracemalloc library.\n",
    "    #tracemalloc.start()\n",
    "    # memory used at program start.\n",
    "    #print(f'tracemalloc memory used in GBs [current, peak] = {[mem_value / (1024**3) for mem_value in tracemalloc.get_traced_memory()]}')\n",
    "    # memory used by tracemalloc.\n",
    "    #print(f'memory used by tracemalloc in GBs = {tracemalloc.get_tracemalloc_memory() / (1024**3)}')\n",
    "    #print('-' * 5 + '\\n')\n",
    "\n",
    "    # gets velocity for all points inside the user specified box.\n",
    "    iso_data = IsoCube(cube_num = cube_num, cube_dimensions = cube_dimensions, cube_title = cube_title)\n",
    "\n",
    "    # data constants\n",
    "    # bytes per value associated with a datapoint.\n",
    "    bytes_per_datapoint = 4\n",
    "    # maximum data size allowed to be retrieved, in gigabytes (GB).\n",
    "    max_data_size = 3.0\n",
    "    # smallest sub-box size to recursively shrink to. if this size box is only partially contained in the user-specified box, then\n",
    "    # the (X, Y, Z) points outside of the user-specified box will be trimmed.  the value is the length of one side of the cube.\n",
    "    voxel_side_length = 8\n",
    "\n",
    "    # the number of values to read per datapoint. for pressure data this value is 1.  for velocity\n",
    "    # data this value is 3, because there is a velocity measurement along each axis.\n",
    "    num_values_per_datapoint = 1\n",
    "    if var == 'vel':\n",
    "        num_values_per_datapoint = 3\n",
    "\n",
    "    # used for determining the indices in the output array for each X, Y, Z datapoint.\n",
    "    x_min = x_range[0]\n",
    "    y_min = y_range[0]\n",
    "    z_min = z_range[0]\n",
    "\n",
    "    # used for creating the 3-D output array using numpy, and also checking that the user did not request too much data.\n",
    "    x_axis_length = x_range[1] - x_range[0] + 1\n",
    "    y_axis_length = y_range[1] - y_range[0] + 1\n",
    "    z_axis_length = z_range[1] - z_range[0] + 1\n",
    "\n",
    "    # total number of datapoints, used for checking if the user requested too much data.\n",
    "    num_datapoints = x_axis_length * y_axis_length * z_axis_length\n",
    "    # total size of data, in GBs, requested by the user's box.\n",
    "    requested_data_size = (num_datapoints * bytes_per_datapoint * num_values_per_datapoint) / float(1024**3)\n",
    "    # maximum number of datapoints that can be read in. currently set to 3 GBs worth of datapoints.\n",
    "    max_datapoints = int((max_data_size * (1024**3)) / (bytes_per_datapoint * float(num_values_per_datapoint)))\n",
    "    # approximate max size of a cube representing the maximum data points. this number is rounded down.\n",
    "    approx_max_cube = int(max_datapoints**(1/3))\n",
    "\n",
    "    if requested_data_size > max_data_size:\n",
    "        raise ValueError(f'Please specify a box with fewer than {max_datapoints} data points. This represents an approximate cube size ' + \\\n",
    "                         f'of ({approx_max_cube} x {approx_max_cube} x {approx_max_cube}).')\n",
    "\n",
    "    # begin processing of data.\n",
    "    # -----\n",
    "    print('Note: For smaller boxes, up to 256-cubed, processing will take approximately 20 seconds or less.  For larger boxes, e.g. 512-cubed, processing ' + \\\n",
    "          'will take approximately 2 minutes or more...\\n' + '-' * 5)\n",
    "    \n",
    "    # -----\n",
    "    # get a map of the database files where all the data points are in.\n",
    "    print('\\nStep 1: Determining which database files the user-specified box is found in...\\n' + '-' * 25)\n",
    "\n",
    "    #%time user_single_db_boxes = iso_data.identifySingleDatabaseFileSubBoxes(x_range, y_range, z_range, var, timepoint)\n",
    "    user_single_db_boxes = iso_data.identifySingleDatabaseFileSubBoxes(x_range, y_range, z_range, var, timepoint)\n",
    "\n",
    "    print(f'number of database files that the user-specified box is found in:\\n{len(user_single_db_boxes)}\\n')\n",
    "    # for db_file in sorted(user_single_db_boxes, key = lambda x: os.path.basename(x)):\n",
    "    #     print(db_file)\n",
    "    #     print(user_single_db_boxes[db_file])\n",
    "\n",
    "    print('Successfully completed.\\n' + '-' * 5)\n",
    "    \n",
    "    # -----\n",
    "    # recursively break down each single file box into sub-boxes, each of which is exactly one of the sub-divided cubes of the database file.\n",
    "    print('\\nStep 2: Recursively breaking down the portion of the user-specified box in each database file into voxels...\\n' + '-' * 25)\n",
    "    \n",
    "    sub_db_boxes = {}\n",
    "    for db_file in sorted(user_single_db_boxes, key = lambda x: os.path.basename(x)):\n",
    "        user_db_box = user_single_db_boxes[db_file][0]\n",
    "\n",
    "        #%time sub_boxes, read_byte_sequences = iso_data.identifySubBoxesInFile(user_db_box, var, timepoint, voxel_side_length)\n",
    "        morton_voxels_to_read = iso_data.identifySubBoxesInFile(user_db_box, var, timepoint, voxel_side_length)\n",
    "\n",
    "        sub_db_boxes[db_file] = morton_voxels_to_read\n",
    "        \n",
    "    print('sub-box statistics for the database file(s):\\n-')\n",
    "    print(f'minimum number of sub-boxes to read in a database file:\\n{np.min([len(sub_db_boxes[db_file]) for db_file in sub_db_boxes])}')\n",
    "    print(f'maximum number of sub-boxes to read in a database file:\\n{np.max([len(sub_db_boxes[db_file]) for db_file in sub_db_boxes])}\\n')\n",
    "    #for db_file in sorted(sub_db_boxes, key = lambda x: os.path.basename(x)):\n",
    "    #    print(db_file)\n",
    "    #    print(f'number of boxes = {len(sub_db_boxes[db_file])}')\n",
    "    #    #print(sub_db_boxes[db_file])\n",
    "    \n",
    "    print('Successfully completed.\\n' + '-' * 5)\n",
    "\n",
    "    # -----\n",
    "    # read the data.\n",
    "    print('\\nStep 3: Reading the data from all of the database files and storing the values into a matrix...\\n' + '-' * 25)\n",
    "    \n",
    "    # pre-fill the output data 3-d array that will be filled with the data that is read in.\n",
    "    output_data = np.empty((x_axis_length, y_axis_length, z_axis_length, num_values_per_datapoint), dtype = 'f')\n",
    "    \n",
    "    # iterate over the database files and morton sub-boxes to read the data from.\n",
    "    for db_file in sub_db_boxes:\n",
    "        morton_voxels_to_read = sub_db_boxes[db_file]\n",
    "        db_minLim = user_single_db_boxes[db_file][1]\n",
    "\n",
    "        iso_data.getISO_Points(db_file, morton_voxels_to_read, output_data, \\\n",
    "                               db_minLim, x_min, y_min, z_min, \\\n",
    "                               num_values_per_datapoint, bytes_per_datapoint, voxel_side_length, verbose = False)\n",
    "    \n",
    "    # checks to make sure that data was read in for all points.\n",
    "    if None in output_data:\n",
    "        raise Exception(f'output_data was not filled correctly')\n",
    "    \n",
    "    print('\\nSuccessfully completed.\\n' + '-' * 5)\n",
    "    \n",
    "    # -----\n",
    "    # write the output file.\n",
    "    print('\\nStep 4: Writing the output matrix to a hdf5 file...\\n' + '-' * 25)\n",
    "    \n",
    "    # write output_data to a hdf5 file.\n",
    "    # the output filename specifies the title of the cube, and the x-, y-, and z-ranges so that the file is unique. 1 is added to all of the \n",
    "    # ranges because python uses 0-based indices, and the output is desired to be 1-based indices.\n",
    "    output_filename = f'{cube_title}_x{x_range[0] + 1}-{x_range[1] + 1}_y{y_range[0] + 1}-{y_range[1] + 1}_z{z_range[0] + 1}-{z_range[1] + 1}'\n",
    "    # formats the dataset name for the hdf5 output file. \"untitled\" is a placeholder.\n",
    "    dataset_name = 'Untitled'\n",
    "    if var == 'vel':\n",
    "        dataset_name = 'Velocity'\n",
    "    elif var == 'pr':\n",
    "        dataset_name = 'Pressure'\n",
    "        \n",
    "    # adds the timpoint information, formatted with leading zeros out to 1000, to dataset_name. 1 is added to timepoint because python uses\n",
    "    # 0-based indices, and the output is desired to be 1-based indices.\n",
    "    dataset_name += '_' + str(timepoint + 1).zfill(4)\n",
    "    \n",
    "    # writes the output file.\n",
    "    iso_data.writeOutputMatrixToHDF5(output_data, output_path, output_filename, dataset_name)\n",
    "    \n",
    "    print('\\nSuccessfully completed.\\n' + '-' * 5)\n",
    "    \n",
    "    # memory used during processing.\n",
    "    #print(f'\\ntracemalloc memory used in GBs [current, peak] = {[mem_value / (1024**3) for mem_value in tracemalloc.get_traced_memory()]}')\n",
    "    # memory used by tracemalloc.\n",
    "    #print(f'memory used by tracemalloc in GBs = {tracemalloc.get_tracemalloc_memory() / (1024**3)}')\n",
    "    # stopping the tracemalloc library.\n",
    "    #tracemalloc.stop()\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    # see how long the program took to run\n",
    "    print(f'\\ntotal time elapsed = {round(end_time - start_time, 3)} seconds ({round((end_time - start_time) / 60, 3)} minutes)')\n",
    "    \n",
    "    print('\\nData processing pipeline has completed successfully.\\n' + '-' * 5)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: For smaller boxes, up to 256-cubed, processing will take approximately 20 seconds or less.  For larger boxes, e.g. 512-cubed, processing will take approximately 2 minutes or more...\n",
      "-----\n",
      "\n",
      "Step 1: Determining which database files the user-specified box is found in...\n",
      "-------------------------\n",
      "number of database files that the user-specified box is found in:\n",
      "1\n",
      "\n",
      "Successfully completed.\n",
      "-----\n",
      "\n",
      "Step 2: Recursively breaking down the portion of the user-specified box in each database file into voxels...\n",
      "-------------------------\n",
      "sub-box statistics for the database file(s):\n",
      "-\n",
      "minimum number of sub-boxes to read in a database file:\n",
      "312\n",
      "maximum number of sub-boxes to read in a database file:\n",
      "312\n",
      "\n",
      "Successfully completed.\n",
      "-----\n",
      "\n",
      "Step 3: Reading the data from all of the database files and storing the values into a matrix...\n",
      "-------------------------\n",
      "\n",
      "Successfully completed.\n",
      "-----\n",
      "\n",
      "Step 4: Writing the output matrix to a hdf5 file...\n",
      "-------------------------\n",
      "\n",
      "Successfully completed.\n",
      "-----\n",
      "\n",
      "total time elapsed = 3.784 seconds (0.063 minutes)\n",
      "\n",
      "Data processing pipeline has completed successfully.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# user-defined parameters for processing data.\n",
    "# size of the model cube that data will be retrieved for.\n",
    "cube_num = 8192\n",
    "# number of dimensions that model data exists in.  default is 3 (i.e. X, Y, and Z dimensions).\n",
    "cube_dimensions = 3\n",
    "# turbulence dataset name, e.g. \"isotropic8192\" or \"isotropic1024fine\".\n",
    "cube_title = 'isotropic8192'\n",
    "# folder name to write the hdf5 output files to.\n",
    "output_folder_name = 'turbulence_hdf5_output'\n",
    "\n",
    "# user specified box rather for which data values will be retrieved for each point inside the box.\n",
    "x_range = [0, 511]\n",
    "y_range = [0, 511]\n",
    "z_range = [0, 511]\n",
    "\n",
    "# variable of interest, currently set to velocity.\n",
    "var = 'vel'\n",
    "# time point.\n",
    "timepoint = 0\n",
    "\n",
    "# process the data.\n",
    "# -----\n",
    "# create the output folder directory if it does not already exist.\n",
    "dir_path = os.path.dirname(os.path.realpath('__file__')) + '/'\n",
    "output_path = dir_path + output_folder_name + '/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "# parse the database files, generate the output_data matrix, and write the matrix to an hdf5 file.\n",
    "output_data = processData(cube_num, cube_dimensions, cube_title, output_path, x_range, y_range, z_range, var, timepoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data value (\"vel\") for datapoint (3, 4, 7):\n",
      "[0.3287481 0.8840852 4.188107 ]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# retrieve the data value for a datapoint (X, Y, Z).\n",
    "X = 3\n",
    "Y = 4\n",
    "Z = 7\n",
    "\n",
    "data_value = retrieveDataForPoint(X, Y, Z, output_data, x_range, y_range, z_range)\n",
    "\n",
    "print(f'data value (\"{var}\") for datapoint ({X}, {Y}, {Z}):\\n{data_value}\\n' + '-' * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0023009711818284618, 0.0030679615757712823, 0.005368932757599744)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for trials on  http://turbulence.pha.jhu.edu/webquery/query.aspx\n",
    "# converts the X, Y, and Z points to the domain of [0, 2*pi]\n",
    "dxyz=2*math.pi/8192\n",
    "x=X*dxyz\n",
    "y=Y*dxyz\n",
    "z=Z*dxyz\n",
    "# enter these values in UI\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare direct access to cutout\n",
    "To get raw data in HDF5 format one can run a job at http://turbulence.idies.jhu.edu/cutout/jobs.\n",
    "Result will be put on scratch. Here an example reading the result of such a job, using the parameters.txt to find the location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 98/98 [00:17<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ran job x in [1000,1010], y and z in [1,10]\n",
    "#folder='/home/idies/workspace/Temporary/gerard/scratch/jobs/__turbcutout__/20211012/20211012094603-148997/'\n",
    "folder = '/home/idies/workspace/Temporary/mschnau1/scratch/jobs/__turbcutout__/20211112/20211112132339-159781/'\n",
    "p=f'{folder}parameters.txt' \n",
    "with open(p,'r') as f:\n",
    "    pars=json.load(f)\n",
    "pars\n",
    "\n",
    "f=f'{folder}isotropic8192.h5' \n",
    "h5=h5py.File(f,'r')\n",
    "\n",
    "h5['Velocity_0001'].shape\n",
    "\n",
    "x=h5['xcoor']\n",
    "y=h5['ycoor']\n",
    "z=h5['zcoor']\n",
    "vel=h5['Velocity_0001']\n",
    "\n",
    "var='vel'\n",
    "timepoint=pars['ts']-1   # in cutout time starts at 1\n",
    "    \n",
    "# choose an offset in the retrieved cutout\n",
    "#dx = 8; dy = 8; dz = 8;\n",
    "\n",
    "# 1-based index.\n",
    "x_range_dx = [3, 101]\n",
    "y_range_dy = [7, 31]\n",
    "z_range_dz = [8, 21]\n",
    "\n",
    "for dx in tqdm(range(x_range_dx[0], x_range_dx[1])):\n",
    "    for dy in range(y_range_dy[0], y_range_dy[1]):\n",
    "        for dz in range(z_range_dz[0], z_range_dz[1]):\n",
    "            v1=vel[dz,dy,dx,:]\n",
    "\n",
    "            # calculate position in the file\n",
    "            X=pars['xs']+dx-1\n",
    "            Y=pars['ys']+dy-1  # cutout starts at 1\n",
    "            Z=pars['zs']+dz-1\n",
    "\n",
    "            # gets velocity for all points inside the user specified box.\n",
    "            #iso_data = IsoCube(cube_num = 8192, cube_dimensions = 3, cube_title = 'isotropic8192')\n",
    "\n",
    "            #v2 = np.asarray(iso_data.getISO_Point_original(X, Y, Z, var, timepoint, verbose = False))\n",
    "\n",
    "            # data from above code.\n",
    "            v3 = retrieveDataForPoint(X, Y, Z, output_data, x_range, y_range, z_range)\n",
    "            #v3 = output_data[5][5][6]\n",
    "\n",
    "            # hope this would be zeros\n",
    "            #v1-v2\n",
    "\n",
    "            #all_zeros_v1v2 = np.all((v1-v2) == 0)\n",
    "            all_zeros_v1v3 = np.all((v1-v3) == 0)\n",
    "            #all_zeros_v2v3 = np.all((v2-v3) == 0)\n",
    "\n",
    "            #if not (all_zeros_v1v2 and all_zeros_v1v3 and all_zeros_v2v3):\n",
    "            if not all_zeros_v1v3:\n",
    "                print(v1)\n",
    "                print(v3)\n",
    "                raise Exception(f'({X}, {Y}, {Z}) datapoint did not produce the same results between the different methods')\n",
    "                \n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12/12 [00:56<00:00,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compares with my cutout as well. \n",
    "# note: my cutout is ordered (X, Y, Z), as opposed to the website cutout (Z, Y, X). the hdf5 format may require (Z, Y, X), so I may have to change my code.\n",
    "import h5py\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ran job x in [1000,1010], y and z in [1,10]\n",
    "#folder='/home/idies/workspace/Temporary/gerard/scratch/jobs/__turbcutout__/20211012/20211012094603-148997/'\n",
    "folder = '/home/idies/workspace/Temporary/mschnau1/scratch/jobs/__turbcutout__/20211112/20211112150007-159783/'\n",
    "p=f'{folder}parameters.txt' \n",
    "with open(p,'r') as f:\n",
    "    pars=json.load(f)\n",
    "pars\n",
    "\n",
    "f=f'{folder}isotropic8192.h5' \n",
    "h5=h5py.File(f,'r')\n",
    "\n",
    "h5['Velocity_0001'].shape\n",
    "\n",
    "x=h5['xcoor']\n",
    "y=h5['ycoor']\n",
    "z=h5['zcoor']\n",
    "vel=h5['Velocity_0001']\n",
    "\n",
    "# data from the h5 file stored by my algorithm.\n",
    "folder_my = '/home/idies/workspace/Storage/mschnau1/persistent/turbulence_hdf5_output/'\n",
    "\n",
    "f_my=f'{folder_my}isotropic8192_x413-512_y376-512_z387-512.h5' \n",
    "h5_my=h5py.File(f_my,'r')\n",
    "\n",
    "h5_my['Velocity_0001'].shape\n",
    "\n",
    "vel_my=h5_my['Velocity_0001']\n",
    "\n",
    "var='vel'\n",
    "timepoint=pars['ts']-1   # in cutout time starts at 1\n",
    "    \n",
    "# choose an offset in the retrieved cutout\n",
    "#dx = 8; dy = 8; dz = 8;\n",
    "\n",
    "# 1-based index.\n",
    "x_range_dx = [500, 512]\n",
    "y_range_dy = [450, 512]\n",
    "z_range_dz = [435, 512]\n",
    "\n",
    "for dx in tqdm(range(x_range_dx[0], x_range_dx[1])):\n",
    "    for dy in range(y_range_dy[0], y_range_dy[1]):\n",
    "        for dz in range(z_range_dz[0], z_range_dz[1]):\n",
    "            v1=vel[dz,dy,dx,:]\n",
    "            v1_my = vel_my[dx - x_range[0],dy - y_range[0],dz - z_range[0],:]\n",
    "\n",
    "            # calculate position in the file\n",
    "            X=pars['xs']+dx-1\n",
    "            Y=pars['ys']+dy-1  # cutout starts at 1\n",
    "            Z=pars['zs']+dz-1\n",
    "\n",
    "            # gets velocity for all points inside the user specified box.\n",
    "            #iso_data = IsoCube(cube_num = 8192, cube_dimensions = 3, cube_title = 'isotropic8192')\n",
    "\n",
    "            #v2 = np.asarray(iso_data.getISO_Point_original(X, Y, Z, var, timepoint, verbose = False))\n",
    "\n",
    "            # data from above code.\n",
    "            v3 = retrieveDataForPoint(X, Y, Z, output_data, x_range, y_range, z_range)\n",
    "            #v3 = output_data[5][5][6]\n",
    "\n",
    "            # hope this would be zeros\n",
    "            #v1-v2\n",
    "\n",
    "            #all_zeros_v1v2 = np.all((v1-v2) == 0)\n",
    "            all_zeros_v1v3 = np.all((v1-v3) == 0)\n",
    "            all_zeros_v1v1my = np.all((v1-v1_my) == 0)\n",
    "            #all_zeros_v2v3 = np.all((v2-v3) == 0)\n",
    "\n",
    "            #if not (all_zeros_v1v2 and all_zeros_v1v3 and all_zeros_v2v3):\n",
    "            if not (all_zeros_v1v3 and all_zeros_v1v1my):\n",
    "                print(v1)\n",
    "                print(v1_my)\n",
    "                print(v3)\n",
    "                raise Exception(f'({X}, {Y}, {Z}) datapoint did not produce the same results between the different methods')\n",
    "                \n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FullOnly</th>\n",
       "      <th>KeyMin</th>\n",
       "      <th>KeyMax</th>\n",
       "      <th>ShiftX</th>\n",
       "      <th>ShiftY</th>\n",
       "      <th>ShiftZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>134217728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>134217730</td>\n",
       "      <td>134217730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>134217732</td>\n",
       "      <td>134217732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>134217734</td>\n",
       "      <td>134217734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>134217744</td>\n",
       "      <td>134217744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262139</th>\n",
       "      <td>False</td>\n",
       "      <td>249261478</td>\n",
       "      <td>249261478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262140</th>\n",
       "      <td>False</td>\n",
       "      <td>249261488</td>\n",
       "      <td>249261488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262141</th>\n",
       "      <td>False</td>\n",
       "      <td>249261490</td>\n",
       "      <td>249261490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262142</th>\n",
       "      <td>False</td>\n",
       "      <td>249261492</td>\n",
       "      <td>249261492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262143</th>\n",
       "      <td>False</td>\n",
       "      <td>249261494</td>\n",
       "      <td>249261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262144 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FullOnly     KeyMin     KeyMax  ShiftX  ShiftY  ShiftZ\n",
       "0          False          0  134217728       0       0       0\n",
       "1          False  134217730  134217730       0       0       0\n",
       "2          False  134217732  134217732       0       0       0\n",
       "3          False  134217734  134217734       0       0       0\n",
       "4          False  134217744  134217744       0       0       0\n",
       "...          ...        ...        ...     ...     ...     ...\n",
       "262139     False  249261478  249261478       0       0       0\n",
       "262140     False  249261488  249261488       0       0       0\n",
       "262141     False  249261490  249261490       0       0       0\n",
       "262142     False  249261492  249261492       0       0       0\n",
       "262143     False  249261494  249261494       0       0       0\n",
       "\n",
       "[262144 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import SciServer.CasJobs as cj\n",
    "sql = \"\"\"\n",
    "declare @box dbo.Box=dbo.Box::New(0,0,0,8192,8192,8192)\n",
    "declare @query dbo.Shape=dbo.Shape::Parse('BOX[0,0,0,513,512,512]')\n",
    "select * from dbo.fcover('M',13,@box,1,@query)\n",
    "\"\"\"\n",
    "\n",
    "df = cj.executeQuery(sql, \"simulationDB\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
